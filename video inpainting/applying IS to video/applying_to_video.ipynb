{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN8r1FFKl5eG1itcJksAhd4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amirrezahmi/Video-Inpainting-and-Voice-Cloning/blob/main/video%20inpainting/applying%20IS%20to%20video/applying_to_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ej5d1apoen9n",
        "outputId": "4b86f72f-4ca1-4214-8dce-54192ff890b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.14.0 transformers-4.34.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-K-g9SMf6nF",
        "outputId": "cb5b2e87-6db2-43bc-b530-b481194d47db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.27.5)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (17.0.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.9.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "m-AQlWJHgNmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def video_to_frames(video_path, frames_dir):\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "    count = 0\n",
        "    while video.isOpened():\n",
        "        ret, frame = video.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        cv2.imwrite(frames_dir + \"/{:d}.png\".format(count), frame)\n",
        "        count += 1\n",
        "    video.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    return count\n",
        "\n",
        "frames_count_1 = video_to_frames('/content/video1.mp4', '/content/sample_data/file15')\n",
        "frames_count_2 = video_to_frames('/content/video2.mp4', '/content/sample_data/file16')\n",
        "\n",
        "#assert frames_count_1 == frames_count_2, \"The number of frames in the two videos are not equal.\""
      ],
      "metadata": {
        "id": "dgpWxOOfgMAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the directories\n",
        "dir1 = '/content/sample_data/file15'\n",
        "dir2 = '/content/sample_data/file16'\n",
        "\n",
        "# Get the list of all files in directory 1\n",
        "files_dir1 = set(os.listdir(dir1))\n",
        "\n",
        "# Get the list of all files in directory 2\n",
        "files_dir2 = set(os.listdir(dir2))\n",
        "\n",
        "# Find the files which are in directory 2 but not in directory 1\n",
        "files_to_delete = files_dir2 - files_dir1\n",
        "\n",
        "# Remove these files from directory 2\n",
        "for file in files_to_delete:\n",
        "    file_path = os.path.join(dir2, file)\n",
        "    if os.path.isfile(file_path):\n",
        "        os.remove(file_path)"
      ],
      "metadata": {
        "id": "13e439Udil6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the directories\n",
        "dir2 = '/content/sample_data/file15'\n",
        "dir1 = '/content/sample_data/file16'\n",
        "\n",
        "# Get the list of all files in directory 1\n",
        "files_dir1 = set(os.listdir(dir1))\n",
        "\n",
        "# Get the list of all files in directory 2\n",
        "files_dir2 = set(os.listdir(dir2))\n",
        "\n",
        "# Find the files which are in directory 2 but not in directory 1\n",
        "files_to_delete = files_dir2 - files_dir1\n",
        "\n",
        "# Remove these files from directory 2\n",
        "for file in files_to_delete:\n",
        "    file_path = os.path.join(dir2, file)\n",
        "    if os.path.isfile(file_path):\n",
        "        os.remove(file_path)"
      ],
      "metadata": {
        "id": "0bjQpIipis5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Specify the folder where your images are located\n",
        "folder_path = '/content/sample_data/file15'\n",
        "\n",
        "# List all files in the folder\n",
        "files = os.listdir(folder_path)\n",
        "\n",
        "# Sort the files by their numerical names\n",
        "sorted_files = sorted(files, key=lambda x: int(x.split('.')[0]))\n",
        "\n",
        "# Now, sorted_files contains your image filenames in numerical order\n",
        "print(sorted_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-xjWdBeizqs",
        "outputId": "b4fa99ab-6ac2-473e-bbaf-170b5498472e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0.png', '1.png', '2.png', '3.png', '4.png', '5.png', '6.png', '7.png', '8.png', '9.png', '10.png', '11.png', '12.png', '13.png', '14.png', '15.png', '16.png', '17.png', '18.png', '19.png', '20.png', '21.png', '22.png', '23.png', '24.png', '25.png', '26.png', '27.png', '28.png', '29.png', '30.png', '31.png', '32.png', '33.png', '34.png', '35.png', '36.png', '37.png', '38.png', '39.png', '40.png', '41.png', '42.png', '43.png', '44.png', '45.png', '46.png', '47.png', '48.png', '49.png', '50.png', '51.png', '52.png', '53.png', '54.png', '55.png', '56.png', '57.png', '58.png', '59.png', '60.png', '61.png', '62.png', '63.png', '64.png', '65.png', '66.png', '67.png', '68.png', '69.png', '70.png', '71.png', '72.png', '73.png', '74.png', '75.png', '76.png', '77.png', '78.png', '79.png', '80.png', '81.png', '82.png', '83.png', '84.png', '85.png', '86.png', '87.png', '88.png', '89.png', '90.png', '91.png', '92.png', '93.png', '94.png', '95.png', '96.png', '97.png', '98.png', '99.png', '100.png', '101.png', '102.png', '103.png', '104.png', '105.png', '106.png', '107.png', '108.png', '109.png', '110.png', '111.png', '112.png', '113.png', '114.png', '115.png', '116.png', '117.png', '118.png', '119.png', '120.png', '121.png', '122.png', '123.png', '124.png', '125.png', '126.png', '127.png', '128.png', '129.png', '130.png', '131.png', '132.png', '133.png', '134.png', '135.png', '136.png', '137.png', '138.png', '139.png', '140.png', '141.png', '142.png', '143.png', '144.png', '145.png', '146.png', '147.png', '148.png', '149.png', '150.png', '151.png', '152.png', '153.png', '154.png', '155.png', '156.png', '157.png', '158.png', '159.png', '160.png', '161.png', '162.png', '163.png', '164.png', '165.png', '166.png', '167.png', '168.png', '169.png', '170.png', '171.png', '172.png', '173.png', '174.png', '175.png', '176.png', '177.png', '178.png', '179.png', '180.png', '181.png', '182.png', '183.png', '184.png', '185.png', '186.png', '187.png', '188.png', '189.png', '190.png', '191.png', '192.png', '193.png', '194.png', '195.png', '196.png', '197.png', '198.png', '199.png', '200.png', '201.png', '202.png', '203.png', '204.png', '205.png', '206.png', '207.png', '208.png', '209.png', '210.png', '211.png', '212.png', '213.png', '214.png', '215.png', '216.png', '217.png', '218.png', '219.png', '220.png', '221.png', '222.png', '223.png', '224.png', '225.png', '226.png', '227.png', '228.png', '229.png', '230.png', '231.png', '232.png', '233.png', '234.png', '235.png', '236.png', '237.png', '238.png', '239.png', '240.png', '241.png', '242.png', '243.png', '244.png', '245.png', '246.png', '247.png', '248.png', '249.png', '250.png', '251.png', '252.png', '253.png', '254.png', '255.png', '256.png', '257.png', '258.png', '259.png', '260.png', '261.png', '262.png', '263.png', '264.png', '265.png', '266.png', '267.png', '268.png', '269.png', '270.png', '271.png', '272.png', '273.png', '274.png', '275.png', '276.png', '277.png', '278.png', '279.png', '280.png', '281.png', '282.png', '283.png', '284.png', '285.png', '286.png', '287.png', '288.png', '289.png', '290.png', '291.png', '292.png', '293.png', '294.png', '295.png', '296.png', '297.png', '298.png', '299.png', '300.png', '301.png', '302.png', '303.png', '304.png', '305.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6KkCKobbJAO",
        "outputId": "be1ea222-542d-465f-f461-5e26c64ec867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/detr-resnet-50-panoptic and revision fc15262 (https://huggingface.co/facebook/detr-resnet-50-panoptic).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at facebook/detr-resnet-50-panoptic were not used when initializing DetrForSegmentation: ['detr.model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'detr.model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'detr.model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'detr.model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: LABEL_187\n",
            "1: elephant\n",
            "2: LABEL_193\n",
            "3: person\n",
            "Enter the labels to keep, separated by space: elephant\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load the model for image segmentation\n",
        "model = pipeline(\"image-segmentation\", device=0)\n",
        "\n",
        "# Directory containing frames of the first video\n",
        "frame1_dir = '/content/sample_data/file15'\n",
        "\n",
        "# Directory containing frames of the second video\n",
        "frame2_dir = '/content/sample_data/file16'\n",
        "\n",
        "# Directory to save the output frames\n",
        "output_dir = 'output_frames33'\n",
        "\n",
        "# Ensure the output directory exists\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Get the list of frame files\n",
        "frame_files1 = sorted_files\n",
        "frame_files2 = sorted_files\n",
        "\n",
        "# Ensure the number of frames in both videos are the same\n",
        "assert len(frame_files1) == len(frame_files2), \"The number of frames in both videos must be the same.\"\n",
        "\n",
        "# Get the labels to keep from the first frame\n",
        "results = model(os.path.join(frame1_dir, frame_files1[0]))\n",
        "for i, result in enumerate(results):\n",
        "    print(f\"{i}: {result['label']}\")\n",
        "labels_input = input(\"Enter the labels to keep, separated by space: \")\n",
        "labels = labels_input.split()\n",
        "\n",
        "# Loop over each pair of frames\n",
        "for frame_file1, frame_file2 in zip(frame_files1, frame_files2):\n",
        "    # Load the frames\n",
        "    frame1 = Image.open(os.path.join(frame1_dir, frame_file1))\n",
        "    frame2 = Image.open(os.path.join(frame2_dir, frame_file2))\n",
        "\n",
        "    # Ensure both frames have the same size\n",
        "    if frame1.size != frame2.size:\n",
        "        frame1 = frame1.resize(frame2.size)\n",
        "\n",
        "    # Segment the first frame\n",
        "    results = model(frame1)\n",
        "\n",
        "    # Create a dictionary mapping labels to masks\n",
        "    label_to_mask = {result['label']: result['mask'] for result in results}\n",
        "\n",
        "    # Initialize a binary mask with all zeros\n",
        "    combined_binary_mask = np.zeros_like(np.array(results[0][\"mask\"]))\n",
        "\n",
        "    for label in labels:\n",
        "        # Check if the label is in the results\n",
        "        if label not in label_to_mask:\n",
        "            continue\n",
        "\n",
        "        # Convert the mask to a numpy array\n",
        "        mask_array = np.array(label_to_mask[label])\n",
        "\n",
        "        # Apply a threshold to convert the grayscale mask to binary\n",
        "        threshold = 128  # Adjust this threshold value as needed\n",
        "        binary_mask = np.where(mask_array >= threshold, 255, 0).astype(np.uint8)\n",
        "\n",
        "        # Combine the binary masks using the logical OR operation\n",
        "        combined_binary_mask = np.logical_or(combined_binary_mask, binary_mask)\n",
        "\n",
        "    # Convert the combined binary mask to uint8\n",
        "    combined_binary_mask = combined_binary_mask.astype(np.uint8) * 255\n",
        "\n",
        "    # Create a transparent image\n",
        "    transparent_image = Image.new(\"RGBA\", frame1.size, (0, 0, 0, 0))\n",
        "\n",
        "    # Paste the original image onto the transparent image using the combined binary mask\n",
        "    transparent_image.paste(frame1, (0, 0), mask=Image.fromarray(combined_binary_mask))\n",
        "\n",
        "    # Overlay the transparent image onto the second frame\n",
        "    frame2.paste(transparent_image, (0, 0), transparent_image)\n",
        "\n",
        "    # Save the output frame\n",
        "    frame2.save(os.path.join(output_dir, frame_file2))\n",
        "\n",
        "# Combine the output frames back into a video\n",
        "frame_files = sorted_files\n",
        "\n",
        "frame0 = cv2.imread(os.path.join(output_dir, frame_files[0]))\n",
        "height, width, layers = frame0.shape\n",
        "video = cv2.VideoWriter('output_video1.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 30, (width,height))\n",
        "for frame_file in frame_files:\n",
        "    video.write(cv2.imread(os.path.join(output_dir, frame_file)))\n",
        "video.release()\n"
      ]
    }
  ]
}